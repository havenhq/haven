{
    "model_config":{
        "model_name": "mosaicml/mpt-7b-chat",
        "tokenizer_name": "mosaicml/mpt-7b-chat",
        "instruction_prefix": "<|im_start|>user\n",
        "output_prefix": "<|im_end|><|im_start|>assistant\n",
        "stop_tokens": ["<|im_end|>"],
        "context_size": 28000,
        "dtype": "bfloat16"
    },


    "lora_training_config":{
     
    },

    "full_training_config":{

    },


    "inference_config":{
        "16bit":{
            "initialization_args":{
                "trust_remote_code": true,
                "low_cpu_mem_usage": true
            },
            "instances": ["T4", "A10"]
        }
    }

}
