syntax = "proto3";

package haven;

message Empty {}

service Haven {
	// Setup (first time starting the manager)
	rpc Setup(SetupRequest) returns (SetupResponse) {}

	// Generate text from a prompt.
	rpc ChatCompletion(ChatCompletionRequest) returns (stream ChatCompletionResponse) {}

	// Get the list of models and their descriptions.
	rpc ListModels(Empty) returns (ListModelsResponse) {}

	// Get the list of workers and their statuses.
	rpc ListWorkers(Empty) returns (ListWorkersResponse) {}

	// Inference worker management.
	rpc CreateInferenceWorker(CreateInferenceWorkerRequest) returns (InferenceWorker) {}
	rpc PauseInferenceWorker(InferenceWorker) returns (InferenceWorker) {}
	rpc ResumeInferenceWorker(InferenceWorker) returns (InferenceWorker) {}
	rpc DeleteInferenceWorker(InferenceWorker) returns (InferenceWorker) {}
}

message SetupRequest {
	optional string key_file = 1;
}

message SetupResponse {
	// Used for warnings when running on an outdated version.
	optional string message = 1;
}

enum Role {
	ASSISTANT = 0;
	USER = 1;
}

message Message {
	Role role = 1;
	string content = 2;
}

message ChatCompletionRequest {
	string worker_name = 1;
	repeated Message messages = 2;

	optional int32 max_tokens = 3;
	optional float top_p = 4;
	optional int32 top_k = 5;
	optional float temperature = 6;
}

message ChatCompletionResponse {
	string text = 1;
}

enum Status {
	ONLINE = 0;
	UNREACHABLE = 1;
	PAUSED = 2;
	ERROR = 3;
}

message Model {
	string name = 1;
}

message ListModelsResponse {
	repeated Model models = 1;
}

message Worker {
	string worker_name = 1;
	Status status = 2;
}

message ListWorkersResponse {
	repeated Worker workers = 1;
}

enum GpuType {
	A100 = 0;
	A100_80GB = 1;
	T4 = 2;
}

message CreateInferenceWorkerRequest {
	string model_name = 1;
	string quantization = 2;
	optional string worker_name = 3;
	optional GpuType gpu_type = 4;
	optional int32 gpu_count = 6;
}

message InferenceWorker {
	string worker_name = 1;
}
